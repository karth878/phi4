base_model: microsoft/Phi-4-reasoning-plus
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer

# Model loading configuration - OPTIMIZED FOR H100
load_in_8bit: false
load_in_4bit: false  # Disabled - use full precision with H100's memory
strict: false

# Dataset configuration
datasets:
  - path: ./prepared_all_memory_types_corrected
    type: chat_template
    field_messages: messages
    message_field_role: role
    message_field_content: content

dataset_prepared_path:
val_set_size: 0.05
output_dir: ./phi4_axolotl_outputs_fixed

# Sequence and packing configuration
sequence_len: 8192
sample_packing: false
pad_to_sequence_len: true
eval_packing_ratio: 1.0

# LoRA adapter configuration
adapter: lora
lora_model_dir:
lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_fan_in_fan_out: false
lora_target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj

# Weights & Biases logging
wandb_project: phi4-axolotl-training-fixed
wandb_entity:
wandb_watch:
wandb_name: phi4-informius-axolotl-fixed-h100-optimized
wandb_log_model:
report_to: wandb

# Training hyperparameters - OPTIMIZED FOR H100
gradient_accumulation_steps: 1  # Reduced since micro_batch_size increased
micro_batch_size: 16  # Dramatically increased from 1 - start here, can go higher
num_epochs: 3
optimizer: adamw_torch
lr_scheduler: cosine
learning_rate: 0.0002
warmup_steps: 100

# Training configuration - H100 OPTIMIZED
train_on_inputs: true
group_by_length: false
bf16: true      # H100 optimized precision
fp16: false     # Use bf16 instead
tf32: true      # Enable for H100 performance boost

# Memory optimization - DISABLED FOR H100
gradient_checkpointing: false  # MAJOR SPEEDUP - disabled due to abundant memory
gradient_checkpointing_kwargs:
  use_reentrant: false

# Attention configuration
flash_attention: true
xformers_attention: false

# Logging and evaluation
logging_steps: 10
eval_steps: 50
save_steps: 100
eval_strategy: steps
save_strategy: steps
save_total_limit: 3

# Evaluation configuration
eval_max_new_tokens: 4096
eval_table_size:
eval_sample_packing: false

# Saving configuration
save_safetensors: true

# Regularization
weight_decay: 0.01
max_grad_norm: 1.0
ddp_find_unused_parameters: false

# Resume training - ADD YOUR CHECKPOINT PATH
resume_from_checkpoint: ./phi4_axolotl_outputs_fixed/checkpoint-500  # UPDATE THIS TO YOUR LATEST CHECKPOINT
early_stopping_patience:
local_rank:
device_map:

# Debugging
debug:
deepspeed:
fsdp:
fsdp_config:

# Special tokens - use model defaults
special_tokens:

# Chat template - let Axolotl auto-detect
chat_template:

# Generation configuration (for inference reference)
# Note: These are not used during training but good to document
# generation_config:
#   max_new_tokens: 4096
#   temperature: 0.7
#   do_sample: true
#   top_p: 0.95
#   top_k: 50
#   repetition_penalty: 1.1
#   length_penalty: 1.0
#   early_stopping: false
#   no_repeat_ngram_size: 3